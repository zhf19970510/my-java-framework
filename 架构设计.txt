高性能复杂度解决：拆分系统
高可用复杂度解决：备份冗余
高扩展复杂度解决：正确预测变化，完美封装变化。

架构设计的目的：应对复杂度

架构设计的原则：
合适原则
简单原则
演化原则

大型网站特点：
高并发、大流量
高可用
海量数据
用户分布广、网络情况复杂
安全环境复杂
需求变化多端
演进式发展（非一蹴而就）


系统衡量指标：
性能
    吞吐量：tps，qps
    并发数：宽泛。并发用户数，连接数，请求数，线程数
    平均响应时间：请求发出，响应结束。
    阿姆达尔定理：
        加速比：原来的时间（Told）-> 现在的时间（Tnew），Rm = Told / Tnew
        增强比例：p=模块/系统
        T‘ new = T'old * [(1-p) + p / Rm]
可用性
    规定的时间内，不发生故障的概率。
        固有可靠性>使用可靠性
    影响可用性的因素？
        复杂性、多变性、环境未知
    如何优化可用性？
        消除单点依赖，做负载均衡
        将串联改成并联
        read/write through
伸缩性
    应用服务器
    缓存服务器
    数据库服务器
扩展性
    功能性需求
    做法：事件驱动（消息队列）、分布式

安全性


整体优化思路：
大事化小
前置处理
后置处理
加快处理
优化的点：从用户使用我们系统开始，到我们响应用户为止。

前端优化概述：
减少不必要的传输
    合并http请求：nginx-http-concat-master,tengine:mod_concat
    启用压缩:客户端和服务端配合使用，thumbnailator，图片转base64
    减少cookie：静态资源单独放在一个域名下。
    斟酌的顺序
该前置的前置
    能放在客户端处理的放在客户端处理
该缓存的缓存
    1. http缓存
        cache-control
            public[响应]private[响应]no-cache[请求、响应]、no-store[请求、响应]
            有效时长：
            max-age=:秒，s-maxage=秒，max-stale=秒，min-fresh=秒
            缓存过期思路：
            更改文件名；后端先验证缓存的有效性

    2. 客户端的缓存
能前端做前端做，减少和后端的交互。


DNS优化
DNS解析过程：
域名记录的类型：
A：address. 域名 -> IP
CNAME: 域名 -> 域名
NS：域名 -> 域名解析服务器

域名服务器的类型：
根，权威，LDNS
DNS解析过程，我们的方案：
提前做好DNS缓存
    接口尽量在一个域名下
    预备获取 dns prefetch
    <meta http-equiv="x-dns-prefetch-control" content="on" />
    <meta rel="dns-prefetch" href="baidu.com" />
一个域名可以映射多个IP,做负载均衡


CDN优化：
CDN概述：
    Content Delivery network
CDN结构：源站，cdn节点（缓存节点，边缘节点）
CDN原理：
总结：client 先通过 LDNS 找到DNS服务器，根据ip地址找到距离最近的DNS节点，然后client去DNS节点取数据或文件，如果没有找到再去源站找数据，最后返回给client

CDN扩展：（多地址直连）
源站：动态内容，让客户端分发到合适的源站
1. 类注册中心
2. 类规则中心

代理：
正向代理：用户端配置代理

反向代理：服务端配置代理

伸缩性思考：
DNS
反向代理
http重定向（不提倡，因为需要经过http重定向服务器获取真是web服务地址，http重定向服务器成为性能瓶颈）
IP层负载均衡：通过网络层修改请求目标地址进行负载均衡。SNAT:源地址转换
数据链路层负载均衡：三角传输模式，通过修改mac地址，直接路由DR，比如LVS


负载均衡算法：
轮询：RR Round Robin
加权轮询： weighted Round Robin
随机：
最少连接：
源地址散列：Source Hashing
根据请求来源的地址进行hash运算


网关：
作用：
协议转换
路由转发
负载均衡
安全性

xss攻击：
反射型xss攻击
持久型xss攻击
预防方案：
1. 消毒：字符替换
2. HttpOnly：浏览器禁止页面中的javascript访问带有HttpOnly的cookie，HttpOnly并不是直接预防xss攻击的，而是预防xss攻击之后窃取用户的cookie。
response.setHeader("Set-Cookie", "HttpOnly");

SQL注入：
1. 消毒
2. 预编译 #


CSRF:跨站点请求伪造
1. Token校验
2. 错误信息包装
3. 设置上传文件的白名单


安全性：信息加密
单向加密：可以预防脱库，防止泄露用户信息
    MD5,SHA
通过对不同输入的信息，
对称加密：算法简单，效率比较高，系统的开销比较小，适合对大量数据的加密。
    Cookie
    应用场合：信息安全传输，数字签名
非对称加密：
    使用的加密和解密的秘钥是不一样的，公钥和私钥
    用公钥加密的必须用私钥进行解开
    反之，用公钥加密的必须用私钥进行解密。
    理论上，不可能通过公钥计算出私钥。
    应用场合：信息安全传输，数字签名
    信息+摘要+秘文    :单项加密+非对称加密
    常用的非对称加密算法：RSA

    将秘钥和加密算法放在一台独立的服务器上
    加解密的算法放入应用程序当中


信息过滤与反垃圾
1. 识别出要过滤的信息，识别有害信息，有害信息发送方
2. 对识别出的信息进行处理



应用服务器性能优化：
1. 应用集群
    并行和并发
    集群整体并发：同质化服务器
    无状态节点集群
2. 分布式缓存
3. 异步操作
4. 代码优化


单一服务节点集群：
比如某一个节点只对某一批用户服务，另一个节点对另外一批用户服务，节点直接数据缓存，但不共享

信息共享节点集群
多个server，用同样的存储

信息一致性节点集群：cap
网络8大谬论：
1. 网络总是可靠的。
2. 没有延迟
3. 带宽无限
4. 网络总是安全的
5. 网络拓扑不变
6. 只有一个管理员
7. 传输代价为0
8. 网络是同构的
保证p的方法：冗余

服务内并发：
多进程：每个进程之间资源独立，进程之间存在很强的隔离性
多线程：
多协程：

线程数的选择：没有准确的数字
线程数 = cpu核数*cpu的利用率 * （1+w/c)
                               等待时间 比 计算时间

top
loadaverage: 核数*使用率，如1.0,1.  1,1.  2
                           1min  5min  15min
                            几个临界点需要检查问题（0.7*核数, 1*核数, 5*核数）

根据上面概述：
CPU密集型 ~= cpu核数 * 1
I/O密集型 ~= cpu核数 * 2



分布式缓存：
分流
并发

导流：将数据引向存储在缓存介质中，以提高速度

缓存收益：
缓存数据的选择：1. 读多写少，2. 原查询时间很长
增加缓存后，系统时间：T（key）+T（查询value）+T（转换）+（1-p）*T（查询）
缓存中最重要的是命中率，

缓存key的生成：
快速生成（生成key，检索key）
防止重复:选择合适的算法，比如SHA-2:SHA-224\SHA-256\SHA-384\SHA-512
算法越复杂，生成的位数越长，则越耗时，但是重复率越低，所以快速生成和防止重复成反比。


缓存值的生成：
序列化数据
对象数据


缓存的风险：
频繁修改的数据用缓存（读写比 > 2:1)
没有热点的访问
数据不一致与脏读
缓存可用性
缓存预热
缓存击穿、穿透


缓存更新机制概述：
调用方、缓存、数据提供方、
主动更新
被动更新

排列组合：
1. 数据提供方更新
2. 更新缓存，删除缓存
组合：（前提，如果读操作的时候缓存中没有，则去数据库中查，并把查询的结果放入缓存中）
1. 先更新缓存，再更新数据库 （x)
2. 先更新数据库，再更新缓存 （从线程安全和业务角度都不合适）
3. 先删除缓存，再更新数据库  （写比读慢，极有可能读到更新前的数据，刷新到缓存的还是老数据）这里可以用延时双删的机制，当更新完数据库后，再次删除缓存。
4. 先更新数据库，再删除缓存 （√）：可以给缓存设置一个有效期（Cache Aside）
    出现第4种可能会出现问题需要满足的条件：
    4.1 读操作的时候缓存中无数据
    4.2 读操作的时候有一个写正在进行
    4.3 读操作在数据提供方读取数据的时长，大于写操作。
    4.4 在读写操作的时候，读取到的是旧值


缓存更新机制：
Read/Write Through:
    调用者只和缓存打交道，
    写操作的时候，先写入缓存，再写入数据库
    读操作的时候，只读缓存
    所以需要在缓存启动时，自身完成将所有数据从数据提供方读入缓存（初始化）
Write behind
    只是对上面的Write Through做了小小的改动，写入缓存后，写入数据库的过程是异步的。既然是异步就可能会有问题，所以可以在写库失败后加入重试机制。



缓存清理机制：
清理的时间点：
清理什么东西：

时效式清理机制：
数目阈值式清理机制：FIFO、LRU（LinkedHashMap）
SoftReference<>
最近经常访问的数据用LRU，最近不常访问的数据用软引用


缓存击穿：缓存中存在一个被高频率访问的数据，如果该数据在缓存中突然失效，则大量的请求会被倾泄到数据提供方上去，
    LRU、Read/Write Through、Write behind
缓存穿透：
缓存雪崩：
缓存预热：(Read/Write Through、Write behind)


缓存位置：
级联系统缓存 位置
客户端缓存：
静态缓存（cdn，磁盘上）
服务缓存（网关、负载均衡、具体的服务等）
数据库缓存：
数据库本身缓存（方案上，冗余字段，ods-中间表，历史表 show variables like 'have_query_cache'）
根据复用的时间段：选取缓存的数据，缓存的位置


写缓存：
在调用方和数据处理方增加缓存，响应及时反馈给用户，然后缓存可以将数据慢慢传递给数据处理方处理，做到流量削峰的作用，保护好了系统，也给用户比较好的响应。但是在要求实时性比较高的系统，这种方式要慎用。
发布订阅：redis，MQ       将实时性要求不高的数据延迟进行
考虑采用写缓存的因素：用户的体验，系统业务对实时性和数据一致性的要求。


异步操作：任何可以晚点做的事都应该晚点做，能拖就拖
提升扩展性和系统性能


代码优化：
多线程：需要考虑修改共有资源导致数据错乱的问题（资源：对象，文件，内存，数据库，现成）
避免多线程带来的安全和数据问题方案：
将对象设计成无状态对象（无状态对象：对象本身不存储状态的信息）
使用局部对象。
并发资源使用锁。

资源复用：
数据库连接，网络通信连接，线程、复杂的对象
单例模式：减少对象的创建来减少资源（常亮存储的类，工具类）
对象池：复用对象的实例，减少对象的创建和资源的消耗（比如：数据库连接池


存储设计：
读写分离：将数据库访问的压力分散到数据库集群中的多个数据存储的节点上，缺点：没有分散存储的压力
分库分表：
主从复制延迟的解决方案：
1. 写操作后的读操作，发给主库去读
redis 用户 1 主库，如果下次访问是1，删除redis
2. 关键业务操作指向主库，非关键业务采用读写分离
3. 读从机失败后，再读一次主机。二次读取。


分库分表：
业务：
性能：
数据隔离：
开始分库分表之前需要考虑：路由、拼接
常用路由方法：范围、hash

分库分表的问题：
分布式ID的问题：全局唯一，高性能，高可用，好接入。（uuid，自增id，批量ID,redis生成ID,雪花算法，uidGenerator，leaf)


拆分维度的问题：以什么维度进行拆分，需要根据业务以及用户偏向使用的字段上去拆分。
join问题：在分库分表的系统中，进行单表查询，在代码中做逻辑处理，也可以借助Es，加快检索效率。
事务问题：XA
成本问题：

表分区：
1. 对外还是一个逻辑表
2. 将不同的分区文件放到不同的磁盘上
range，list，hash
注意：
1. 做分区，要结合查询规则
2. 分区的条件，放到where语句中
带来的问题：
表分区的个数限制：1024
表分区过多后，会出现较多的跨区查询。


应用保护：
优先保证核心业务，优先保证绝大部分业务
降级、熔断、限流、隔离
系统后门接口。位：10010，切面
自动降级：时机，如何降级
时机：超时，失败次数，故障降级，限流降级
如何做（手段）：停止读取数据库，从缓存中读取近似结果（精确-> 近似），用静态结果，同步转异步，功能裁剪，禁止写操作，分用户降级（爬虫用户和正常用户），工作量证明降级（POW)


熔断：
策略：
根据请求的失败率。状态：打开，半开，关闭

根据响应时间

限流：
请求：访问总量，单位时间的阈值
资源：内部资源（如何确定关键资源，如何确定资源的阈值），池化技术
限流延伸：
排队：排队的模块，服务模块，调度模块
过载保护：tomcat
固定的时间窗口：固定的时间段内，固定的请求数
漏桶算法：需要衡量好服务器的处理能力
令牌桶算法：
初始化
请求处理
（令牌不足，令牌充足）
定时器


隔离：
数据隔离
机器隔离
线程池隔离
信号量隔离
进程隔离
集群隔离
机房隔离
读写隔离
动静隔离
爬虫隔离
热点隔离


恢复：
应用预热

异地多活：
标准：每个地方的系统都是活跃的，随时切换。
代价：架构复杂度，成本
评估标准：影响力，成本，收益
分类：同城异区，跨城异地，跨国异地

异地多活的设计角度：
1. 保证核心业务的异地多活
2. 核心数据做最终一致
3. 允许多种手段的同步数据，如果没有同步到，二次读取，回源读取，重新生成数据
4. 只保证大部分用户可用
技术无法解决，从业务入手

异地多活设计步骤：
1. 业务分级（访问量，主业务，投入产出）
2. 数据分级：（数据量，唯一性，数据更新的实时性，可丢失性，可恢复性
3. 数据同步：（存储组件同步，消息队列同步，重复生成）
4. 异常处理：同步延迟，数据丢失，数据不一致
    处理方案：多通道同步，日志记录，用户补偿


架构意识：
关键问题可能不是出在技术上
简明清晰的沟通
不存在放之四海而皆准的解决方案
提前关注性能问题
先确保解决方案简单可用，再考虑通用性和复用性